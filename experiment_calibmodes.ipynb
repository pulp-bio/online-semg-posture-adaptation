{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from online_semg_posture_adaptation import dataset as ds\n",
    "from online_semg_posture_adaptation.learning import mlpuniboinail as mui\n",
    "from online_semg_posture_adaptation.learning import learning as learn\n",
    "from online_semg_posture_adaptation.learning import quantization as quant\n",
    "from online_semg_posture_adaptation import protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLING_FACTOR = 1\n",
    "\n",
    "NUM_CALIB_REPETITIONS = 5\n",
    "\n",
    "NUM_EPOCHS_FP = 4\n",
    "QUANTIZE = True\n",
    "NUM_EPOCHS_QAT = 8\n",
    "INPUT_SCALE = 0.999\n",
    "\n",
    "RESULTS_FILENAME = 'results_adaptation.pkl'\n",
    "RESULTS_DIR_PATH = './results/'\n",
    "RESULTS_FILE_FULLPATH = RESULTS_DIR_PATH + RESULTS_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure for storing the results\n",
    "\n",
    "results = {'subject': {}}\n",
    "\n",
    "for idx_subject in range(ds.NUM_SUBJECTS):\n",
    "\n",
    "    results['subject'][idx_subject] = {'day': {}}\n",
    "\n",
    "    for idx_day in range(ds.NUM_DAYS):\n",
    "\n",
    "        results['subject'][idx_subject]['day'][idx_day] = {'reference_posture': {}}\n",
    "\n",
    "        for idx_ref_posture in range(ds.NUM_POSTURES):\n",
    "\n",
    "            results['subject'][idx_subject]['day'][idx_day]['reference_posture'][idx_ref_posture] = {'target_posture': {}}\n",
    "\n",
    "            for idx_tgt_posture in range(ds.NUM_POSTURES):\n",
    "\n",
    "                results['subject'][idx_subject]['day'][idx_day]['reference_posture'][idx_ref_posture]['target_posture'][idx_tgt_posture] = {\n",
    "                    'recalibration_mode': {\n",
    "                        'none': {'calibration': {}, 'validation': {}},\n",
    "                        'pca_online': {'calibration': {}, 'validation': {}},\n",
    "                    },\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_subject, idx_day, idx_ref_posture in itertools.product(\n",
    "    range(ds.NUM_SUBJECTS), range(ds.NUM_DAYS), range(ds.NUM_POSTURES)\n",
    "):\n",
    "    \n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # print a header\n",
    "    print(\n",
    "        f\"\\n\"\n",
    "        f\"------------------------------------------------------------------\\n\"\n",
    "        f\"SUBJECT\\t{idx_subject + 1 :d}/{ds.NUM_SUBJECTS:d}\\n\"\n",
    "        f\"DAY\\t{idx_day + 1 :d}/{ds.NUM_DAYS:d}\\n\"\n",
    "        f\"POSTURE\\t{idx_ref_posture + 1 :d}/{ds.NUM_POSTURES:d} AS REFERENCE\\n\"\n",
    "        f\"(all indices are one-based)\\n\"\n",
    "        f\"------------------------------------------------------------------\\n\"\n",
    "        f\"\\n\"\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # load training data\n",
    "    train_session_data_dict = ds.load_session(\n",
    "        idx_subject, idx_day, idx_ref_posture)\n",
    "    xtrain = train_session_data_dict['emg']\n",
    "    ytrain = train_session_data_dict['relabel']\n",
    "    del train_session_data_dict\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # downsampling\n",
    "    xtrain = xtrain[:, ::DOWNSAMPLING_FACTOR]\n",
    "    ytrain = ytrain[::DOWNSAMPLING_FACTOR]\n",
    "\n",
    "    # standard scaling and de-correlation, as preprocessing before training\n",
    "    stdscaler_train = StandardScaler()\n",
    "    xtrain_stdscaled = stdscaler_train.fit_transform(xtrain.T).T\n",
    "    del xtrain\n",
    "    pca_train = PCA(n_components=ds.NUM_CHANNELS, whiten=False)\n",
    "    xtrain_pc = pca_train.fit_transform(xtrain_stdscaled.T).T\n",
    "    del xtrain_stdscaled\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # MLP training and validation\n",
    "\n",
    "    mlp = mui.MLPUniboINAIL()\n",
    "    mui.summarize(mlp)\n",
    "\n",
    "    # full-precision training\n",
    "    mlp, history, yout_train, yout_valid = learn.do_training(\n",
    "        xtrain=xtrain_pc,\n",
    "        ytrain=ytrain,\n",
    "        model=mlp,\n",
    "        xvalid=None,\n",
    "        yvalid=None,\n",
    "        num_epochs=NUM_EPOCHS_FP,\n",
    "    )\n",
    "    # Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT)\n",
    "    if QUANTIZE:\n",
    "        (\n",
    "            mlp_q,\n",
    "            output_scale,\n",
    "            history_q,\n",
    "            metrics_train_q,\n",
    "            _,  # (in general, this is metrics_valid_q)\n",
    "            yout_train_q,\n",
    "            _,  # (in general, this is yout_valid_q)\n",
    "        ) = quant.quantlib_flow(\n",
    "            xtrain=xtrain_pc,\n",
    "            ytrain=ytrain,\n",
    "            model=mlp,\n",
    "            xvalid=None,\n",
    "            yvalid=None,\n",
    "            do_qat=True,\n",
    "            num_epochs_qat=NUM_EPOCHS_QAT,\n",
    "            input_scale=INPUT_SCALE,\n",
    "            export=False,\n",
    "            onnx_filename=None,\n",
    "        )\n",
    "        mlp = mlp_q  # replace the model\n",
    "        del mlp_q\n",
    "    else:\n",
    "        output_scale = 1.0\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # \"tgt posture\" stands for \"target posture\"\n",
    "    for idx_tgt_posture in range(ds.NUM_POSTURES):\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # print a header\n",
    "        print(\n",
    "            f\"\\n\"\n",
    "            f\"--------------------------------------------------------------\\n\"\n",
    "            f\"TARGET POSTURE {idx_tgt_posture + 1 :d}\\n\"\n",
    "            f\"(trained on {idx_ref_posture + 1 :d})\\n\"\n",
    "            f\"--------------------------------------------------------------\\n\"\n",
    "            f\"\\n\"\n",
    "        )\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # Do the two experiments:\n",
    "        # - no adaptation\n",
    "        # - refit the PCA online\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # load calibration and validation data\n",
    "\n",
    "        calibvalid_session_data_dict = ds.load_session(\n",
    "            idx_subject, idx_day, idx_tgt_posture)\n",
    "\n",
    "        emg_calibvalid = calibvalid_session_data_dict['emg']\n",
    "        relabel_calibvalid = calibvalid_session_data_dict['relabel']\n",
    "        gesture_counter_calibvalid = \\\n",
    "            calibvalid_session_data_dict['gesture_counter']\n",
    "        del calibvalid_session_data_dict\n",
    "\n",
    "        xcalib, ycalib, xvalid, yvalid = ds.split_into_calib_and_valid(\n",
    "            emg=emg_calibvalid,\n",
    "            relabel=relabel_calibvalid,\n",
    "            gesture_counter=gesture_counter_calibvalid,\n",
    "            num_calib_repetitions=NUM_CALIB_REPETITIONS,\n",
    "        )\n",
    "        del emg_calibvalid, relabel_calibvalid, gesture_counter_calibvalid\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # downsampling\n",
    "        # NB: frozen standard scaling is included in the function\n",
    "        # calibration_experiment\n",
    "        xcalib = xcalib[:, ::DOWNSAMPLING_FACTOR]\n",
    "        xvalid = xvalid[:, ::DOWNSAMPLING_FACTOR]\n",
    "        ycalib = ycalib[::DOWNSAMPLING_FACTOR]\n",
    "        yvalid = yvalid[::DOWNSAMPLING_FACTOR]\n",
    "        \n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # no calibration\n",
    "\n",
    "        adapt_flag = False\n",
    "        \n",
    "        metrics_calib, metrics_valid = protocol.calibration_experiment(\n",
    "            xcalib=xcalib,\n",
    "            ycalib=ycalib,\n",
    "            xvalid=xvalid,\n",
    "            yvalid=yvalid,\n",
    "            adapt_flag=adapt_flag,\n",
    "            stdscaler_train=stdscaler_train,\n",
    "            pca_train=pca_train,\n",
    "            model=mlp,\n",
    "            output_scale=output_scale,\n",
    "        )\n",
    "\n",
    "        print('\\nNO REFIT\\n')\n",
    "        print('CALIB METRICS')\n",
    "        print(metrics_calib)\n",
    "        print('VALID METRICS')\n",
    "        print(metrics_valid)\n",
    "\n",
    "        # store results\n",
    "        results['subject'][idx_subject]['day'][idx_day]['reference_posture'][idx_ref_posture][\n",
    "            'target_posture'][idx_tgt_posture]['recalibration_mode']['none']['calibration'] = metrics_calib\n",
    "        results['subject'][idx_subject]['day'][idx_day]['reference_posture'][idx_ref_posture][\n",
    "            'target_posture'][idx_tgt_posture]['recalibration_mode']['none']['validation'] = metrics_valid\n",
    "        del adapt_flag, metrics_calib, metrics_valid\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # online PCA\n",
    "\n",
    "        adapt_flag = True\n",
    "\n",
    "        metrics_calib, metrics_valid = protocol.calibration_experiment(\n",
    "            xcalib=xcalib,\n",
    "            ycalib=ycalib,\n",
    "            xvalid=xvalid,\n",
    "            yvalid=yvalid,\n",
    "            adapt_flag=adapt_flag,\n",
    "            stdscaler_train=stdscaler_train,\n",
    "            pca_train=pca_train,  # used to initialize, reorder, and match sign\n",
    "            model=mlp,\n",
    "            output_scale=output_scale,\n",
    "        )\n",
    "\n",
    "        print('\\nONLINE PCA\\n')\n",
    "        print('CALIB METRICS')\n",
    "        print(metrics_calib)\n",
    "        print('VALID METRICS')\n",
    "        print(metrics_valid)\n",
    "\n",
    "        # store results\n",
    "        results['subject'][idx_subject]['day'][idx_day]['reference_posture'][idx_ref_posture][\n",
    "            'target_posture'][idx_tgt_posture]['recalibration_mode']['pca_online']['calibration'] = metrics_calib\n",
    "        results['subject'][idx_subject]['day'][idx_day]['reference_posture'][idx_ref_posture][\n",
    "            'target_posture'][idx_tgt_posture]['recalibration_mode']['pca_online']['validation'] = metrics_valid\n",
    "        del adapt_flag, metrics_calib, metrics_valid\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "        \n",
    "        # save to file\n",
    "        # save the updated results dictionary after each validation\n",
    "        results_outer_dict = {'results': results}\n",
    "        Path(RESULTS_DIR_PATH).mkdir(parents=True, exist_ok=True)\n",
    "        with open(RESULTS_FILE_FULLPATH, 'wb') as f:\n",
    "            pickle.dump(results_outer_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
