{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Author(s):\n",
    "    Marcello Zanghieri <marcello.zanghieri2@unibo.it>\n",
    "    \n",
    "    Copyright (C) 2023 University of Bologna and ETH Zurich\n",
    "    \n",
    "    Licensed under the GNU Lesser General Public License (LGPL), Version 2.1\n",
    "    (the \"License\");\n",
    "    you may not use this file except in compliance with the License.\n",
    "    You may obtain a copy of the License at\n",
    "    \n",
    "        https://www.gnu.org/licenses/lgpl-2.1.txt\n",
    "    \n",
    "    Unless required by applicable law or agreed to in writing, software\n",
    "    distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "    See the License for the specific language governing permissions and\n",
    "    limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from online_semg_posture_adaptation import dataset as ds\n",
    "from online_semg_posture_adaptation.learning import mlpuniboinail as mui\n",
    "from online_semg_posture_adaptation.learning import learning as learn\n",
    "from online_semg_posture_adaptation.learning import quantization as quant\n",
    "from online_semg_posture_adaptation import protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLING_FACTOR = 1\n",
    "\n",
    "NUM_CALIB_REPETITIONS = 5\n",
    "\n",
    "NUM_EPOCHS_FP = 4\n",
    "QUANTIZE = True\n",
    "NUM_EPOCHS_QAT = 8\n",
    "INPUT_SCALE = 0.999\n",
    "\n",
    "RESULTS_FILENAME = 'results_adaptation.pkl'\n",
    "RESULTS_DIR_PATH = './results/'\n",
    "RESULTS_FILE_FULLPATH = RESULTS_DIR_PATH + RESULTS_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure for storing the results\n",
    "\n",
    "results = {'subject': {}}\n",
    "\n",
    "for idx_subject in range(ds.NUM_SUBJECTS):\n",
    "\n",
    "    results['subject'][idx_subject] = {'day': {}}\n",
    "\n",
    "    for idx_day in range(ds.NUM_DAYS):\n",
    "\n",
    "        results['subject'][idx_subject]['day'][idx_day] = {'reference_posture': {}}\n",
    "\n",
    "        for idx_ref_posture in range(ds.NUM_POSTURES):\n",
    "\n",
    "            results['subject'][idx_subject]['day'][idx_day]['reference_posture'][idx_ref_posture] = {'target_posture': {}}\n",
    "\n",
    "            for idx_tgt_posture in range(ds.NUM_POSTURES):\n",
    "\n",
    "                results['subject'][idx_subject]['day'][idx_day]['reference_posture'][idx_ref_posture]['target_posture'][idx_tgt_posture] = {\n",
    "                    'recalibration_mode': {\n",
    "                        'none': {'calibration': {}, 'validation': {}},\n",
    "                        'pca_online': {'calibration': {}, 'validation': {}},\n",
    "                    },\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_subject, idx_day, idx_ref_posture in itertools.product(\n",
    "    range(ds.NUM_SUBJECTS), range(ds.NUM_DAYS), range(ds.NUM_POSTURES)\n",
    "):\n",
    "    \n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # print a header\n",
    "    print(\n",
    "        f\"\\n\"\n",
    "        f\"------------------------------------------------------------------\\n\"\n",
    "        f\"SUBJECT\\t{idx_subject + 1 :d}/{ds.NUM_SUBJECTS:d}\\n\"\n",
    "        f\"DAY\\t{idx_day + 1 :d}/{ds.NUM_DAYS:d}\\n\"\n",
    "        f\"POSTURE\\t{idx_ref_posture + 1 :d}/{ds.NUM_POSTURES:d} AS REFERENCE\\n\"\n",
    "        f\"(all indices are one-based)\\n\"\n",
    "        f\"------------------------------------------------------------------\\n\"\n",
    "        f\"\\n\"\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # load training data\n",
    "    train_session_data_dict = ds.load_session(\n",
    "        idx_subject, idx_day, idx_ref_posture)\n",
    "    xtrain = train_session_data_dict['emg']\n",
    "    ytrain = train_session_data_dict['relabel']\n",
    "    del train_session_data_dict\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # downsampling\n",
    "    xtrain = xtrain[:, ::DOWNSAMPLING_FACTOR]\n",
    "    ytrain = ytrain[::DOWNSAMPLING_FACTOR]\n",
    "\n",
    "    # standard scaling and de-correlation, as preprocessing before training\n",
    "    stdscaler_train = StandardScaler()\n",
    "    xtrain_stdscaled = stdscaler_train.fit_transform(xtrain.T).T\n",
    "    del xtrain\n",
    "    pca_train = PCA(n_components=ds.NUM_CHANNELS, whiten=False)\n",
    "    xtrain_pc = pca_train.fit_transform(xtrain_stdscaled.T).T\n",
    "    del xtrain_stdscaled\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # MLP training and validation\n",
    "\n",
    "    mlp = mui.MLPUniboINAIL()\n",
    "    mui.summarize(mlp)\n",
    "\n",
    "    # full-precision training\n",
    "    mlp, history, yout_train, yout_valid = learn.do_training(\n",
    "        xtrain=xtrain_pc,\n",
    "        ytrain=ytrain,\n",
    "        model=mlp,\n",
    "        xvalid=None,\n",
    "        yvalid=None,\n",
    "        num_epochs=NUM_EPOCHS_FP,\n",
    "    )\n",
    "    # Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT)\n",
    "    if QUANTIZE:\n",
    "        (\n",
    "            mlp_q,\n",
    "            output_scale,\n",
    "            history_q,\n",
    "            metrics_train_q,\n",
    "            _,  # (in general, this is metrics_valid_q)\n",
    "            yout_train_q,\n",
    "            _,  # (in general, this is yout_valid_q)\n",
    "        ) = quant.quantlib_flow(\n",
    "            xtrain=xtrain_pc,\n",
    "            ytrain=ytrain,\n",
    "            model=mlp,\n",
    "            xvalid=None,\n",
    "            yvalid=None,\n",
    "            do_qat=True,\n",
    "            num_epochs_qat=NUM_EPOCHS_QAT,\n",
    "            input_scale=INPUT_SCALE,\n",
    "            export=False,\n",
    "            onnx_filename=None,\n",
    "        )\n",
    "        mlp = mlp_q  # replace the model\n",
    "        del mlp_q\n",
    "    else:\n",
    "        output_scale = 1.0\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # \"tgt posture\" stands for \"target posture\"\n",
    "    for idx_tgt_posture in range(ds.NUM_POSTURES):\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # print a header\n",
    "        print(\n",
    "            f\"\\n\"\n",
    "            f\"--------------------------------------------------------------\\n\"\n",
    "            f\"TARGET POSTURE {idx_tgt_posture + 1 :d}\\n\"\n",
    "            f\"(trained on {idx_ref_posture + 1 :d})\\n\"\n",
    "            f\"--------------------------------------------------------------\\n\"\n",
    "            f\"\\n\"\n",
    "        )\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # Do the two experiments:\n",
    "        # - no adaptation\n",
    "        # - refit the PCA online\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # load calibration and validation data\n",
    "\n",
    "        calibvalid_session_data_dict = ds.load_session(\n",
    "            idx_subject, idx_day, idx_tgt_posture)\n",
    "\n",
    "        emg_calibvalid = calibvalid_session_data_dict['emg']\n",
    "        relabel_calibvalid = calibvalid_session_data_dict['relabel']\n",
    "        gesture_counter_calibvalid = \\\n",
    "            calibvalid_session_data_dict['gesture_counter']\n",
    "        del calibvalid_session_data_dict\n",
    "\n",
    "        xcalib, ycalib, xvalid, yvalid = ds.split_into_calib_and_valid(\n",
    "            emg=emg_calibvalid,\n",
    "            relabel=relabel_calibvalid,\n",
    "            gesture_counter=gesture_counter_calibvalid,\n",
    "            num_calib_repetitions=NUM_CALIB_REPETITIONS,\n",
    "        )\n",
    "        del emg_calibvalid, relabel_calibvalid, gesture_counter_calibvalid\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # downsampling\n",
    "        # NB: frozen standard scaling is included in the function\n",
    "        # calibration_experiment\n",
    "        xcalib = xcalib[:, ::DOWNSAMPLING_FACTOR]\n",
    "        xvalid = xvalid[:, ::DOWNSAMPLING_FACTOR]\n",
    "        ycalib = ycalib[::DOWNSAMPLING_FACTOR]\n",
    "        yvalid = yvalid[::DOWNSAMPLING_FACTOR]\n",
    "        \n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # no calibration\n",
    "\n",
    "        adapt_flag = False\n",
    "        \n",
    "        metrics_calib, metrics_valid = protocol.calibration_experiment(\n",
    "            xcalib=xcalib,\n",
    "            ycalib=ycalib,\n",
    "            xvalid=xvalid,\n",
    "            yvalid=yvalid,\n",
    "            adapt_flag=adapt_flag,\n",
    "            stdscaler_train=stdscaler_train,\n",
    "            pca_train=pca_train,\n",
    "            model=mlp,\n",
    "            output_scale=output_scale,\n",
    "        )\n",
    "\n",
    "        print('\\nNO REFIT\\n')\n",
    "        print('CALIB METRICS')\n",
    "        print(metrics_calib)\n",
    "        print('VALID METRICS')\n",
    "        print(metrics_valid)\n",
    "\n",
    "        # store results\n",
    "        results['subject'][idx_subject]['day'][idx_day]['reference_posture'][idx_ref_posture][\n",
    "            'target_posture'][idx_tgt_posture]['recalibration_mode']['none']['calibration'] = metrics_calib\n",
    "        results['subject'][idx_subject]['day'][idx_day]['reference_posture'][idx_ref_posture][\n",
    "            'target_posture'][idx_tgt_posture]['recalibration_mode']['none']['validation'] = metrics_valid\n",
    "        del adapt_flag, metrics_calib, metrics_valid\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # online PCA\n",
    "\n",
    "        adapt_flag = True\n",
    "\n",
    "        metrics_calib, metrics_valid = protocol.calibration_experiment(\n",
    "            xcalib=xcalib,\n",
    "            ycalib=ycalib,\n",
    "            xvalid=xvalid,\n",
    "            yvalid=yvalid,\n",
    "            adapt_flag=adapt_flag,\n",
    "            stdscaler_train=stdscaler_train,\n",
    "            pca_train=pca_train,  # used to initialize, reorder, and match sign\n",
    "            model=mlp,\n",
    "            output_scale=output_scale,\n",
    "        )\n",
    "\n",
    "        print('\\nONLINE PCA\\n')\n",
    "        print('CALIB METRICS')\n",
    "        print(metrics_calib)\n",
    "        print('VALID METRICS')\n",
    "        print(metrics_valid)\n",
    "\n",
    "        # store results\n",
    "        results['subject'][idx_subject]['day'][idx_day]['reference_posture'][idx_ref_posture][\n",
    "            'target_posture'][idx_tgt_posture]['recalibration_mode']['pca_online']['calibration'] = metrics_calib\n",
    "        results['subject'][idx_subject]['day'][idx_day]['reference_posture'][idx_ref_posture][\n",
    "            'target_posture'][idx_tgt_posture]['recalibration_mode']['pca_online']['validation'] = metrics_valid\n",
    "        del adapt_flag, metrics_calib, metrics_valid\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "        \n",
    "        # save to file\n",
    "        # save the updated results dictionary after each validation\n",
    "        results_outer_dict = {'results': results}\n",
    "        Path(RESULTS_DIR_PATH).mkdir(parents=True, exist_ok=True)\n",
    "        with open(RESULTS_FILE_FULLPATH, 'wb') as f:\n",
    "            pickle.dump(results_outer_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
